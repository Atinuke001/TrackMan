{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_json = r'/Users/integrationalpha/Documents/tables'\n",
    "path_to_json2 = r'/Users/integrationalpha/Documents/table2'\n",
    "\n",
    "\n",
    "json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]\n",
    "json_files2 = [pos_json for pos_json in os.listdir(path_to_json2) if pos_json.endswith('.json')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here I define my pandas Dataframe with the columns I want to get from the json\n",
    "\n",
    "jsons_data = pd.DataFrame(columns=['query', 'L', 'M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need both the json and an index number so use enumerate()\n",
    "\n",
    "for index, js in enumerate(json_files):\n",
    "\n",
    "    with open(os.path.join(path_to_json, js)) as json_file:\n",
    "\n",
    "        json_text = json.load(json_file)\n",
    "\n",
    "        content =json_text['query']\n",
    "\n",
    "        to=content['L'][0]['M'] #some of the JSON file do not have 'L' field in that case u have to=content['M']\n",
    "\n",
    "        #to=to.replace('JOIN', 'join')\n",
    "\n",
    "        g=to['from']\n",
    "\n",
    "        y=json.dumps(g)\n",
    "\n",
    "        y=y.replace('join', 'JOIN')\n",
    "\n",
    " \n",
    "\n",
    "        txt=y\n",
    "\n",
    "        replace_list = ['\\n', '(', ')', '*', '=']\n",
    "\n",
    " \n",
    "\n",
    "        for i in replace_list:\n",
    "\n",
    "            txt = txt.replace(i, ' ')\n",
    "\n",
    "        txt = txt.split()\n",
    "\n",
    "        res = []\n",
    "\n",
    "        for i in range(1, len(txt)):\n",
    "\n",
    "            if txt[i-1] in ['{\"S\":', 'JOIN'] and txt[i] != 'select':\n",
    "\n",
    "                res.append(txt[i])\n",
    "\n",
    "               \n",
    "\n",
    "        print(json_files[index], f' table depends on {res}.')\n",
    "\n",
    "               \n",
    "\n",
    "                \n",
    "\n",
    "for index, js in enumerate(json_files2):               \n",
    "\n",
    "    with open(os.path.join(path_to_json2, js)) as json_file2:\n",
    "\n",
    "        json_text2 = json.load(json_file2)\n",
    "\n",
    "        content2 =json_text2['query']\n",
    "\n",
    "        to2=content2['M'] #some of the JSON file do not have 'L' field in that case u have to=content['M']\n",
    "\n",
    "        #to=to.replace('JOIN', 'join')\n",
    "\n",
    "        g2=to2['from']\n",
    "\n",
    "        y2=json.dumps(g2)\n",
    "\n",
    "        y2=y2.replace('join', 'JOIN')\n",
    "\n",
    " \n",
    "\n",
    "        txt2=y2\n",
    "\n",
    "        replace_list = ['\\n', '(', ')', '*', '=']\n",
    "\n",
    " \n",
    "\n",
    "        for i in replace_list:\n",
    "\n",
    "            txt2 = txt2.replace(i, ' ')\n",
    "\n",
    "        txt2 = txt2.split()\n",
    "\n",
    "        res2 = []\n",
    "\n",
    "        for i in range(1, len(txt2)):\n",
    "\n",
    "            if txt2[i-1] in ['{\"S\":', 'JOIN'] and txt2[i] != 'select':\n",
    "\n",
    "                res2.append(txt2[i])               \n",
    "\n",
    "        #print(res)\n",
    "\n",
    "        print(json_files2[index], f' table depends on {res2}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "roots = set()\n",
    "for l in raw.splitlines():\n",
    "    if len(l):\n",
    "        target, prereq = regex.match(l).groups()\n",
    "        if prereq == '\"\"':\n",
    "            roots.add(target)\n",
    "        else:\n",
    "            G.add_edge(prereq, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
